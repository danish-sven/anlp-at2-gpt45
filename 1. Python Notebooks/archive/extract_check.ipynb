{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import codecs\n",
    "import json\n",
    "import re\n",
    "import platform\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = ['Korean', 'English', 'Japanese', 'Mandarin', 'Traditional Chinese',\n",
    "            'Vietnamese', 'German', 'French', 'Other language', 'Spanish',\n",
    "            'Indonesian', 'Russian', 'Arabic', 'Thai', 'Swedish', 'Dutch',\n",
    "            'Hebrew', 'Tagalog', 'Portuguese(Brazil)', 'Cantonese', 'Italian',\n",
    "            'Esperanto', 'Hawaiian', 'Afrikaans', 'Mongolian', 'Hindi', 'Polish',\n",
    "            'Finnish', 'Greek', 'Bihari', 'Farsi', 'Urdu', 'Turkish', 'Portuguese(Portugal)',\n",
    "            'Bulgarian', 'Norwegian', 'Romanian', 'Albanian', 'Ukrainian', 'Catalan',\n",
    "            'Latvian', 'Danish', 'Serbian', 'Slovak', 'Georgian', 'Hungarian', 'Malaysian',\n",
    "            'Icelandic', 'Latin', 'Laotian', 'Croatian', 'Lithuanian', 'Bengali', 'Tongan',\n",
    "            'Slovenian', 'Swahili', 'Irish', 'Czech', 'Estonian', 'Khmer', 'Javanese', 'Sinhalese',\n",
    "            'Sanskrit', 'Armenian', 'Tamil', 'Basque', 'Welsh', 'Bosnian', 'Macedonian', 'Telugu',\n",
    "            'Uzbek', 'Gaelic', 'Azerbaijanian', 'Tibetan', 'Panjabi', 'Marathi', 'Yiddish', 'Ainu',\n",
    "            'Haitian', 'Slavic']\n",
    "color_tags = [\"f-red\", \"f-blue\", \"f-bold\"]\n",
    "sline_tag = \"sline]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    assert platform.python_version_tuple(\n",
    "    )[0] == '3', 'This program supports only python3'\n",
    "    args = parse_args()\n",
    "    data_num = 0\n",
    "    error_num = 0\n",
    "    with codecs.open(args.data_path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            data_num += 1\n",
    "            try:\n",
    "                jsonData = json.loads(line, strict=False)\n",
    "                l2_langs, l1_lang = jsonData[2], jsonData[3]\n",
    "                orig_sents, corr_sents = jsonData[4], jsonData[5]\n",
    "                if (args.l1 == None or args.l1 == l1_lang) and args.l2 in l2_langs:\n",
    "                    outputs = make_dataframe(orig_sents, corr_sents, args)\n",
    "                    outputs.to_csv('outputs.csv')\n",
    "                    # print(outputs)\n",
    "                    # for output in outputs:\n",
    "                    #     print(output)\n",
    "            except:\n",
    "                error_num += 1\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(orig_sents, corr_sents, args):\n",
    "    df = pd.DataFrame(columns=['original', 'corrected'])\n",
    "    for i, orig_sent in enumerate(orig_sents):\n",
    "        orig_sent = orig_sent.replace('\\t', ' ')\n",
    "        if len(corr_sents[i]) > 0:\n",
    "            tag_err = False\n",
    "            for corr_sent in corr_sents[i]:\n",
    "                corr_sent = corr_sent.replace('\\t', ' ')\n",
    "                text, tag_err = delete_tags_color(corr_sent, tag_err, args)\n",
    "                if sline_tag in text:\n",
    "                    text, tag_err = delete_tags_sline(text, tag_err, args)\n",
    "                if not tag_err and text != \"\":\n",
    "                    df['original'].append(orig_sent)\n",
    "                    print(orig_sent)\n",
    "                    df['corrected'].append(text)\n",
    "                    print(text)\n",
    "\n",
    "        else:\n",
    "            df['original'].append(orig_sent)\n",
    "            df['corrected'].append(\"uncorrected\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_tags_sline(text, tag_err, args):\n",
    "    s_sline = \"[sline]\"\n",
    "    e_sline = \"[/sline]\"\n",
    "    if args.tags:\n",
    "        return text\n",
    "    words = text.split(\" \")\n",
    "    total_s = total_e = 0\n",
    "    output_lists, tmp_list = [], []\n",
    "    for word in words:\n",
    "        num_s = word.count(s_sline)\n",
    "        num_e = word.count(e_sline)\n",
    "\n",
    "        total_s += num_s\n",
    "        total_e += num_e\n",
    "        tmp_list.append(word)\n",
    "        if total_s == 0 and total_e == 0:\n",
    "            output_lists.append(word)\n",
    "            tmp_list = []\n",
    "        elif total_s == total_e:\n",
    "            tmp_text = \" \".join(tmp_list)\n",
    "            tmp_text = re.sub(r\"\\[sline\\](.*)\\[\\/sline\\]\", r\"\", tmp_text)\n",
    "            if tmp_text != \"\":\n",
    "                output_lists.append(tmp_text)\n",
    "            total_s = total_e = 0\n",
    "            tmp_list = []\n",
    "    text = \" \".join(output_lists)\n",
    "\n",
    "    if sline_tag in text:\n",
    "        tag_err = True\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text, tag_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_tags_color(text, tag_err, args):\n",
    "    if args.tags:\n",
    "        return text\n",
    "    text = replace_tags(text)\n",
    "\n",
    "    if text == None:\n",
    "        text = \"\"\n",
    "    for tag in color_tags:\n",
    "        s = \"\\[\" + tag + \"\\]\"\n",
    "        e = \"\\[\\/\" + tag + \"\\]\"\n",
    "        text = re.sub(r\"%s\" % s, r\"\", text)\n",
    "        text = re.sub(r\"%s\" % e, r\"\", text)\n",
    "        if tag in text:\n",
    "            tag_err = True\n",
    "\n",
    "    return text, tag_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_tags(s):\n",
    "    s = s.replace(\"[赤]\", \"[f-red]\")\n",
    "    s = s.replace(\"[/赤]\", \"[/f-red]\")\n",
    "    s = s.replace(\"[青]\", \"[f-blue]\")\n",
    "    s = s.replace(\"[/青]\", \"[/f-blue]\")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = r'C:\\Users\\datat\\Documents\\GitHub\\anlp-at2-gpt45\\lang-8-20111007-L1-v2.dat'\n",
    "data_path = r'/Users/stefanhall/Documents/Studies/MDSI/ANLP/AT2/anlp-at2-gpt45/lang-8-20111007-L1-v2.dat'\n",
    "f = codecs.open(data_path, 'r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = 0\n",
    "error_num = 0\n",
    "orig_sentences = []\n",
    "corr_sentences = []\n",
    "\n",
    "df = pd.DataFrame(columns=['original', 'corrected'])\n",
    "\n",
    "for line in f:\n",
    "    data_num +=1\n",
    "    try:\n",
    "        jsonData = json.loads(line, strict=False)\n",
    "        l2_langs, l1_lang = jsonData[2], jsonData[3]\n",
    "        orig_sents, corr_sents = jsonData[4], jsonData[5]\n",
    "        #if \"English\" == l1_lang and \"Japanese\" in l2_langs:\n",
    "        for i, orig_sent in enumerate(orig_sents):\n",
    "            orig_sent = orig_sent.replace('\\t', ' ')\n",
    "            if len(corr_sents[i]) > 0:\n",
    "                tag_err = False\n",
    "                for corr_sent in corr_sents[i]:\n",
    "                    corr_sent = corr_sent.replace('\\t', ' ')\n",
    "                    text, tag_err = delete_tags_color(corr_sent, tag_err)\n",
    "                    if sline_tag in text:\n",
    "                        text, tag_err = delete_tags_sline(text, tag_err)\n",
    "                    if not tag_err and text != \"\":\n",
    "                        df['original'].append(orig_sent)\n",
    "                        df['corrected'].append(text)\n",
    "\n",
    "            else:\n",
    "                df['original'].append(orig_sent)\n",
    "                df['corrected'].append(\"uncorrected\")\n",
    "\n",
    "    except:\n",
    "        error_num += 1\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [original, corrected]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orig_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sent_pair(orig_sents, corr_sents, args):\n",
    "    outputs = []\n",
    "    for i, orig_sent in enumerate(orig_sents):\n",
    "        orig_sent = orig_sent.replace('\\t', ' ')\n",
    "        if len(corr_sents[i]) > 0:\n",
    "            tag_err = False\n",
    "            for corr_sent in corr_sents[i]:\n",
    "                corr_sent = corr_sent.replace('\\t', ' ')\n",
    "                text, tag_err = delete_tags_color(corr_sent, tag_err, args)\n",
    "                if sline_tag in text:\n",
    "                    text, tag_err = delete_tags_sline(text, tag_err, args)\n",
    "                if not tag_err and text != \"\":\n",
    "                    output = orig_sent + \"\\t\" + text\n",
    "                    outputs.append(output)\n",
    "        else:\n",
    "            output = orig_sent + \"\\t\" + orig_sent\n",
    "            outputs.append(output)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_tags_sline(text, tag_err, args):\n",
    "    s_sline = \"[sline]\"\n",
    "    e_sline = \"[/sline]\"\n",
    "    if args.tags:\n",
    "        return text\n",
    "    words = text.split(\" \")\n",
    "    total_s = total_e = 0\n",
    "    output_lists, tmp_list = [], []\n",
    "    for word in words:\n",
    "        num_s = word.count(s_sline)\n",
    "        num_e = word.count(e_sline)\n",
    "\n",
    "        total_s += num_s\n",
    "        total_e += num_e\n",
    "        tmp_list.append(word)\n",
    "        if total_s == 0 and total_e == 0:\n",
    "            output_lists.append(word)\n",
    "            tmp_list = []\n",
    "        elif total_s == total_e:\n",
    "            tmp_text = \" \".join(tmp_list)\n",
    "            tmp_text = re.sub(r\"\\[sline\\](.*)\\[\\/sline\\]\", r\"\", tmp_text)\n",
    "            if tmp_text != \"\":\n",
    "                output_lists.append(tmp_text)\n",
    "            total_s = total_e = 0\n",
    "            tmp_list = []\n",
    "    text = \" \".join(output_lists)\n",
    "\n",
    "    if sline_tag in text:\n",
    "        tag_err = True\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text, tag_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_tags_color(text, tag_err, args):\n",
    "    if args.tags:\n",
    "        return text\n",
    "    text = replace_tags(text)\n",
    "\n",
    "    if text == None:\n",
    "        text = \"\"\n",
    "    for tag in color_tags:\n",
    "        s = \"\\[\" + tag + \"\\]\"\n",
    "        e = \"\\[\\/\" + tag + \"\\]\"\n",
    "        text = re.sub(r\"%s\" % s, r\"\", text)\n",
    "        text = re.sub(r\"%s\" % e, r\"\", text)\n",
    "        if tag in text:\n",
    "            tag_err = True\n",
    "\n",
    "    return text, tag_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_tags(s):\n",
    "    s = s.replace(\"[赤]\", \"[f-red]\")\n",
    "    s = s.replace(\"[/赤]\", \"[/f-red]\")\n",
    "    s = s.replace(\"[青]\", \"[f-blue]\")\n",
    "    s = s.replace(\"[/青]\", \"[/f-blue]\")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-d\", \"--data\", dest=\"data_path\", type=str, metavar='<str>', required=True, help=\"The path to the data set\")\n",
    "    parser.add_argument(\"-l2\", \"--learn-lang\", dest=\"l2\", type=str, metavar='<str>', required=False, default='English', help=\"L2 language\")\n",
    "    parser.add_argument(\"-l1\", \"--native-lang\", dest=\"l1\", type=str, metavar='<str>', required=False, default=None, help=\"L1 language\")\n",
    "    parser.add_argument(\"-tags\", \"--remain-tags\", dest=\"tags\", default=False, action='store_true', help=\"If you want to remain tags (e.g. [f-red]), please use this option\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    assert args.l2 in language\n",
    "    if args.l1 != None:\n",
    "        assert args.l1 in language\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parse_args(-d r'C:\\Users\\datat\\Documents\\GitHub\\anlp-at2-gpt45\\lang-8-20111007-L1-v2.dat')\n",
    "args = parse_args(-d r'/Users/stefanhall/Documents/Studies/MDSI/ANLP/AT2/anlp-at2-gpt45/lang-8-20111007-L1-v2.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
